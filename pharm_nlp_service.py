from fastapi import FastAPI, Query
from pydantic import BaseModel
import logging
import time
import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration
import json
import signal
import sys

from cache_nlp_results import PharmaNameCache  # –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –∏–∑ —à–∞–≥–∞ 1

# –ß–∏—Ç–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞ config.json
def load_config(path="config.json"):
    try:
        with open(path, "r", encoding="utf-8") as f:
            config = json.load(f)
        return config
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return {}

config = load_config()

logging.basicConfig(
    filename='service.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

app = FastAPI()

MODEL_PATH = config.get("model_path", "Goodwill333/T5-NER-Pharm-RU")
AUTOSAVE_INTERVAL = config.get("faiss_autosave_interval", 300)  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5 –º–∏–Ω—É—Ç
DEFAULT_SIMILARITY_THRESHOLD = 0.8

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

tokenizer = T5Tokenizer.from_pretrained(MODEL_PATH)
model = T5ForConditionalGeneration.from_pretrained(MODEL_PATH,  cache_dir=".").to(device)
logging.info("–ú–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω—ã")


def predict(product: str) -> str:
    input_text = "\n".join([
        "–ó–∞–¥–∞–Ω–∏–µ: –ò–∑–≤–ª–µ–∫–∏ —á–∞—Å—Ç–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ –∏–ª–∏ —Ç–æ–≤–∞—Ä–∞ —Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è.",
        f"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: {product}"
    ])
    inputs = tokenizer(input_text, return_tensors="pt", truncation=True).to(device)
    start_time = time.time()
    outputs = model.generate(**inputs, max_length=256, num_beams=2, early_stopping=True)
    end_time = time.time()
    generation_time = end_time - start_time
    message = f"‚è±Ô∏è –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_time:.2f} —Å–µ–∫—É–Ω–¥"
    logging.info(message)
    print(message)
    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
    message2 = f"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: {product}\nüîç decoded: {decoded}"
    logging.info(message2)
    print(message2)
    return decoded.replace("\n", " ").strip()

class PharmaNameService:
    def __init__(self):
        #MODEL_PATH = "./all-MiniLM-L6-v2"
        MODEL_PATH = "./paraphrase-multilingual-MiniLM-L12-v2"
        self.cache = PharmaNameCache(embedding_model_name=MODEL_PATH, autosave_interval=AUTOSAVE_INTERVAL)

    def process_name(self, name, use_cache=True, similarity_threshold=DEFAULT_SIMILARITY_THRESHOLD):
        if use_cache:
            cached_result = self.cache.query_cache(name, similarity_threshold=similarity_threshold)
            if cached_result is not None:
                parsed, cached_name, dist = cached_result
                print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à –¥–ª—è: {name} (–Ω–∞–π–¥–µ–Ω–æ: {cached_name}, dist={dist:.3f})")
                return {"parsed": parsed, "cached_name": cached_name, "from_cache": True, "similarity": float(dist)}

        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å—é T5: {name}")
        result = predict(name)
        self.cache.add_to_cache(name, result)
        return {"parsed": result, "cached_name": None, "from_cache": False, "similarity": None}

service = PharmaNameService()

from pydantic import BaseModel, Field

class ProductRequest(BaseModel):
    product: str
    use_cache: bool = Field(True, description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à")
    similarity_threshold: float = Field(DEFAULT_SIMILARITY_THRESHOLD, ge=0.0, le=1.0, description="–ü–æ—Ä–æ–≥ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –∫—ç—à–∞")

@app.post("/predict")
async def predict_endpoint(request: ProductRequest):
    result = service.process_name(
        request.product,
        use_cache=request.use_cache,
        similarity_threshold=request.similarity_threshold
    )
    return result

def shutdown_handler(signum, frame):
    print("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å–µ—Ä–≤–∏—Å–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à...")
    service.cache.stop_autosave()
    sys.exit(0)

signal.signal(signal.SIGINT, shutdown_handler)
signal.signal(signal.SIGTERM, shutdown_handler)

import uvicorn

if __name__ == "__main__":
    service = PharmaNameService()
    names = [
        "–≠—Å—Å–ª–∏–∞–ª –§–æ—Ä—Ç–µ (–∫–∞–ø—Å. 300 –º–≥ ‚Ññ30 —è—á.–∫–æ–Ω—Ç/–ø/–∫–∞—Ä—Ç. |–ú|) –û–∑–æ–Ω-–†–æ—Å—Å–∏—è",
        "–≠—Å—Å–ª–∏–∞–ª –§–æ—Ä—Ç–µ –∫–∞–ø—Å—É–ª—ã 300–º–≥ —Ö30 —è—á–µ–π–∫–∏.–∫–æ–Ω—Ç –ø –∫–∞—Ä—Ç.",
        "–≠—Å—Å–ª–∏–∞–ª –§–æ—Ä—Ç–µ –∫–∞–ø—Å—É–ª—ã 30–º–≥ —Ö20 —è—á–µ–π–∫–∏.–∫–æ–Ω—Ç –ø –∫–∞—Ä—Ç.",
        "–ü–∞—Ä–∞—Ü–µ—Ç–∞–º–æ–ª 500–º–≥ —Ç–∞–±–ª–µ—Ç–∫–∏"
    ]
    
    for n in names:
        parts = service.process_name(n)
        print(parts)

    uvicorn.run("pharm_nlp_service:app", host="0.0.0.0", port=8000, reload=True)
