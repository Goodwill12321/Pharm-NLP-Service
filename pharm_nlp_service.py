from fastapi import FastAPI
from pydantic import BaseModel
import logging
import time
import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration
import json
import signal
import sys

from cache_nlp_results import PharmaNameCache  # –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å –∏–∑ —à–∞–≥–∞ 1

# –ß–∏—Ç–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞ config.json
def load_config(path="config.json"):
    try:
        with open(path, "r", encoding="utf-8") as f:
            config = json.load(f)
        return config
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return {}

config = load_config()

logging.basicConfig(
    filename='service.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

app = FastAPI()

MODEL_PATH = config.get("model_path", "Goodwill333/T5-NER-Pharm-RU")
AUTOSAVE_INTERVAL = config.get("faiss_autosave_interval", 300)  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5 –º–∏–Ω—É—Ç

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

tokenizer = T5Tokenizer.from_pretrained(MODEL_PATH)
model = T5ForConditionalGeneration.from_pretrained(MODEL_PATH,  cache_dir=".").to(device)
logging.info("–ú–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

class ProductRequest(BaseModel):
    product: str

def predict(product: str) -> str:
    input_text = "\n".join([
        "–ó–∞–¥–∞–Ω–∏–µ: –ò–∑–≤–ª–µ–∫–∏ —á–∞—Å—Ç–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ –∏–ª–∏ —Ç–æ–≤–∞—Ä–∞ —Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è.",
        f"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: {product}"
    ])
    inputs = tokenizer(input_text, return_tensors="pt", truncation=True).to(device)
    start_time = time.time()
    outputs = model.generate(**inputs, max_length=256, num_beams=2, early_stopping=True)
    end_time = time.time()
    generation_time = end_time - start_time
    message = f"‚è±Ô∏è –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_time:.2f} —Å–µ–∫—É–Ω–¥"
    logging.info(message)
    print(message)
    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
    message2 = f"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: {product}\nüîç decoded: {decoded}"
    logging.info(message2)
    print(message2)
    return decoded.replace("\n", " ").strip()

class PharmaNameService:
    def __init__(self):
        self.cache = PharmaNameCache(embedding_model_name="./all-MiniLM-L6-v2", autosave_interval=AUTOSAVE_INTERVAL)

    def process_name(self, name):
        cached_result = self.cache.query_cache(name)
        if cached_result is not None:
            print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à –¥–ª—è: {name}")
            return cached_result
        
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å—é T5: {name}")
        result = predict(name)
        self.cache.add_to_cache(name, result)
        return result

service = PharmaNameService()

@app.post("/predict")
async def predict_endpoint(request: ProductRequest):
    result = service.process_name(request.product)
    return {"result": result}

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞
def shutdown_handler(signum, frame):
    print("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å–µ—Ä–≤–∏—Å–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à...")
    service.cache.stop_autosave()
    sys.exit(0)

signal.signal(signal.SIGINT, shutdown_handler)
signal.signal(signal.SIGTERM, shutdown_handler)

import uvicorn

if __name__ == "__main__":
    service = PharmaNameService()
    names = [
        "–≠—Å—Å–ª–∏–∞–ª –§–æ—Ä—Ç–µ (–∫–∞–ø—Å. 300 –º–≥ ‚Ññ30 —è—á.–∫–æ–Ω—Ç/–ø/–∫–∞—Ä—Ç. |–ú|) –û–∑–æ–Ω-–†–æ—Å—Å–∏—è",
        "–≠—Å—Å–ª–∏–∞–ª –§–æ—Ä—Ç–µ –∫–∞–ø—Å—É–ª—ã 300–º–≥ —Ö30 —è—á–µ–π–∫–∏.–∫–æ–Ω—Ç –ø –∫–∞—Ä—Ç.",
        "–≠—Å—Å–ª–∏–∞–ª –§–æ—Ä—Ç–µ –∫–∞–ø—Å—É–ª—ã 30–º–≥ —Ö20 —è—á–µ–π–∫–∏.–∫–æ–Ω—Ç –ø –∫–∞—Ä—Ç.",
        "–ü–∞—Ä–∞—Ü–µ—Ç–∞–º–æ–ª 500–º–≥ —Ç–∞–±–ª–µ—Ç–∫–∏"
    ]
    
    for n in names:
        parts = service.process_name(n)
        print(parts)

    uvicorn.run("pharm_nlp_service:app", host="127.0.0.1", port=8000, reload=True)
